#! /usr/bin/python3

from bs4 import BeautifulSoup
import os
import requests
import json

join = os.path.join

INSTALL_PATH = join(os.path.expanduser("~"), ".config/nalanda-cli")
SLIDES_PATH = join(os.path.expanduser("~"), "BITS")
DATA_FILE = join(INSTALL_PATH,"data.json")
CONFIG_FILE = join(INSTALL_PATH,"config.json")

subs = json.load(open(join(INSTALL_PATH, "subjects.json")))
SUB_NAMES = list(subs.values())
SUB_URLS = list(subs.keys())
RANGE_SUBS = range(len(SUB_URLS))

ZIP_FILE_LINK = "https://nalanda.bits-pilani.ac.in/mod/folder/download_folder.php"
LOGIN_LINK = "https://nalanda.bits-pilani.ac.in/login/index.php"

URLS = {}
for x in RANGE_SUBS:
    URLS[SUB_URLS[x]] = {
        "resource": [],
        "notice": [],
        "news":[]
    }

for sub in SUB_NAMES:
    sub_path = join(SLIDES_PATH, sub)
    if not os.path.exists(sub_path):
        os.makedirs(sub_path)

def bold(text):
    return "\033[1m" + text + "\033[0m"

try:
    session = requests.session()
    session.post(LOGIN_LINK, data=json.load(open(CONFIG_FILE)))

    links = [BeautifulSoup(session.get(sub).text, "html.parser").find_all("a", {"onclick": ""}) for sub in SUB_URLS]
    for sub in RANGE_SUBS:
        for y in links[sub]:
            url = y.get("href")
            if("resource/view.php?id" in url or "folder/view.php?id=" in url):
                URLS[SUB_URLS[sub]]["resource"].append(url)
            elif("page/view.php?id" in url):
                URLS[SUB_URLS[sub]]["notice"].append(url + "$%^" + y.contents[1].contents[0])
            elif("forum/view.php?id" in url):
                URLS[SUB_URLS[sub]]["news"].append(url)

    for x in SUB_URLS:
        for y in URLS[x]["news"]:
            result = session.get(y)
            soup = BeautifulSoup(result.text, "html.parser")
            discussion_list = soup.find_all("tr", "discussion")
            for url in discussion_list:
                if url.find("td", "topic starter pinned"):
                    URLS[x]["notice"].append(url.contents[0].contents[1].get(
                        "href") + "$%^" + url.contents[0].contents[1].contents[0])
                else:
                    URLS[x]["notice"].append(url.contents[0].contents[0].get(
                        "href") + "$%^" + url.contents[0].contents[0].contents[0])
        URLS[x].pop("news", None)

    DONE_URLS = json.load(open(DATA_FILE))
    new_news = [list(set(URLS[x]["notice"]) - set(DONE_URLS[x]["notice"])) for x in SUB_URLS]
    new_news = [[x.split("$%^") for x in new_news[sub]]for sub in RANGE_SUBS]

    new_slides = [list(set(URLS[x]["resource"]) - set(DONE_URLS[x]["resource"])) for x in SUB_URLS]

    new_sub_index = []
    for x in RANGE_SUBS:
        if new_slides[x]:
            new_sub_index.append(x)
        for y in new_slides[x]:
            if "folder/view" in y:
                id_param = y.split("php")[1]
                result = session.get(ZIP_FILE_LINK + id_param)
            else:
                result = session.get(y)

            file_name = result.headers["content-disposition"].split('e="')[1].split('"')[0]
            with open(join(SLIDES_PATH, SUB_NAMES[x], file_name), "wb") as f:
                f.write(result.content)

    print(bold("News:"))
    if(sum([len(x) for x in new_news])==0):
        print("\tNo updates")
    else:
        for x in RANGE_SUBS:
            if new_news[x]:
                print(bold("\n" + SUB_NAMES[x] + "-"))
            for y in range(len(new_news[x])):
                print("\t" + bold(str(y + 1)) + ". " + new_news[x][y][1] + "\n\t\t" + \
                    new_news[x][y][0])

    print ("\n" + "-" * 60 + "\n")

    print(bold("Lectures:"))
    if not new_sub_index:
        print("\tNo updates")
    else:
        for x in new_sub_index:
            print ("\t" + bold(SUB_NAMES[x]) + " has new updates")
        print ("\tfile://" + SLIDES_PATH)

    json.dump(URLS ,open(DATA_FILE, 'w'), indent=4)

except requests.exceptions.ConnectionError:
    quit("No Internet Connection. Please retry")
except KeyboardInterrupt:
    print("Stopped by user.")
